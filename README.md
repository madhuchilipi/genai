# Project 3: Responsible AI-powered RAG System for GDPR

A comprehensive Retrieval-Augmented Generation (RAG) system implementing responsible AI practices for querying GDPR regulations. This project demonstrates advanced RAG techniques including baseline RAG, memory integration, guardrails, agentic workflows, and graph-enhanced retrieval.

## ğŸ—ï¸ Architecture

The system is built with the following components:

1. **Data Preparation Layer**: GDPR PDF ingestion, intelligent chunking, and FAISS vector indexing
2. **Baseline RAG Pipeline**: Simple retrieval-to-generation workflow
3. **Memory Integration**: Conversational context using LangGraph
4. **Guardrails**: Input/output safety filters and adversarial detection
5. **Agentic RAG**: Multi-tool orchestration with Retriever, Citation Checker, and Summarizer
6. **Graph-Enhanced RAG**: Query rephrasing with anchor and neighboring chunk retrieval
7. **Responsible AI Testing**: Hallucination detection, robustness testing, and LangSmith tracing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Query                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Guardrails (Input Filter)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Query Rephrasing (Graph RAG)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FAISS Vector Retrieval                          â”‚
â”‚          (Anchor + Neighboring Chunks)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Agentic Orchestration (LangGraph)                  â”‚
â”‚      Retriever â†’ Citation Checker â†’ Summarizer               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            LLM Generation with Citations                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Guardrails (Output Filter)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Final Response                              â”‚
â”‚            + LangSmith Trace Export                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Setup

### Prerequisites

- Python 3.9+
- OpenAI API key (for embeddings and LLM)
- LangSmith API key (optional, for tracing)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/madhuchilipi/genai.git
cd genai
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
```bash
# Create a .env file
cp .env.example .env  # If available, or create manually

# Add your API keys
echo "OPENAI_API_KEY=your-openai-api-key-here" >> .env
echo "LANGSMITH_API_KEY=your-langsmith-api-key-here" >> .env  # Optional
echo "LANGCHAIN_TRACING_V2=true" >> .env  # Optional
echo "LANGCHAIN_PROJECT=gdpr-rag" >> .env  # Optional
```

**Note**: The code is designed to work in a "dry-run" mode without API keys. When keys are missing, it will return placeholder outputs to allow for testing and CI/CD without secrets.

## ğŸ“– Usage

### Running Notebooks

The project includes 7 step-by-step notebooks in the `notebooks/` directory:

1. **Data Preparation** (`01_data_preparation.ipynb`): Download GDPR PDF, parse, chunk, embed, and build FAISS index
2. **Baseline RAG** (`02_rag_baseline.ipynb`): Simple retrieval and generation pipeline
3. **Memory Integration** (`03_memory_integration.ipynb`): Add conversational memory with LangGraph
4. **Guardrails** (`04_guardrails.ipynb`): Implement input/output safety filters
5. **Agentic RAG** (`05_agentic_rag.ipynb`): Multi-tool agent orchestration
6. **Graph RAG** (`06_graph_rag.ipynb`): Enhanced retrieval with graph techniques
7. **Responsible AI & Testing** (`07_responsible_ai_and_tests.ipynb`): Adversarial testing and tracing

Run notebooks with:
```bash
jupyter notebook notebooks/
```

### Using Python Modules

The `src/` package provides programmatic access:

```python
from src.data_prep import download_gdpr_pdf, load_and_split, build_and_persist_faiss
from src.rag_baseline import BaselineRAG
from src.guardrails import detect_adversarial_prompt, safe_rewrite

# Prepare data
download_gdpr_pdf("data/gdpr.pdf")
docs = load_and_split("data/gdpr.pdf", strategy="paragraph")
build_and_persist_faiss(docs, "faiss_index/", openai_api_key="your-key")

# Run baseline RAG
rag = BaselineRAG(faiss_path="faiss_index/", openai_api_key="your-key")
answer = rag.query("What are the data subject rights under GDPR?")
print(answer)
```

### Running Tests

```bash
pytest tests/
```

## ğŸ“‹ Deliverables

### Code Deliverables
- âœ… Complete source code in `src/` package
- âœ… 7 Jupyter notebooks demonstrating each milestone
- âœ… Unit tests in `tests/`
- âœ… CI/CD pipeline (`.github/workflows/ci.yml`)

### Documentation
- âœ… README.md (this file)
- âœ… `docs/RESPONSIBLE_AI.md` - Detailed responsible AI practices
- âœ… Inline code documentation and docstrings
- âœ… Notebook markdown cells explaining each step

### Data & Models
- âœ… FAISS vector store (generated from notebooks)
- âœ… GDPR PDF (downloaded programmatically)
- âœ… Embedding model: OpenAI `text-embedding-ada-002`
- âœ… LLM: OpenAI `gpt-3.5-turbo` or `gpt-4`

### Evaluation & Testing
- âœ… Baseline RAG evaluation metrics
- âœ… Adversarial prompt testing
- âœ… Hallucination detection
- âœ… LangSmith trace exports

## ğŸ›¡ï¸ Responsible AI Considerations

This project implements several responsible AI practices:

### 1. **Guardrails**
- **Input Filtering**: Detect and handle adversarial, harmful, or off-topic queries
- **Output Filtering**: Validate responses for safety and relevance
- **Safe Rewriting**: Automatically rewrite unsafe prompts to safe versions

### 2. **Transparency**
- **Citations**: All answers include source document references
- **Tracing**: Full execution traces via LangSmith
- **Explainability**: Clear reasoning chains in agentic workflows

### 3. **Robustness Testing**
- **Adversarial Examples**: Test with edge cases and attack prompts
- **Hallucination Detection**: Compare answers against retrieved context
- **Evaluation Metrics**: Precision, recall, F1 for retrieval quality

### 4. **Privacy & Security**
- **Data Handling**: No PII stored in vector databases
- **API Key Management**: Secure handling via environment variables
- **Audit Logs**: LangSmith traces for compliance review

For detailed information, see [`docs/RESPONSIBLE_AI.md`](docs/RESPONSIBLE_AI.md).

## ğŸ”§ Development

### Project Structure

```
genai/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore                         # Git ignore patterns
â”œâ”€â”€ notebooks/                         # Step-by-step tutorials
â”‚   â”œâ”€â”€ 01_data_preparation.ipynb
â”‚   â”œâ”€â”€ 02_rag_baseline.ipynb
â”‚   â”œâ”€â”€ 03_memory_integration.ipynb
â”‚   â”œâ”€â”€ 04_guardrails.ipynb
â”‚   â”œâ”€â”€ 05_agentic_rag.ipynb
â”‚   â”œâ”€â”€ 06_graph_rag.ipynb
â”‚   â””â”€â”€ 07_responsible_ai_and_tests.ipynb
â”œâ”€â”€ src/                               # Python package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_prep.py                   # Data ingestion and indexing
â”‚   â”œâ”€â”€ rag_baseline.py                # Baseline RAG implementation
â”‚   â”œâ”€â”€ memory.py                      # LangGraph memory helpers
â”‚   â”œâ”€â”€ guardrails.py                  # Safety filters
â”‚   â”œâ”€â”€ agent_rag.py                   # Agentic orchestration
â”‚   â”œâ”€â”€ graph_rag.py                   # Graph-enhanced retrieval
â”‚   â”œâ”€â”€ responsible_ai.py              # Testing and evaluation
â”‚   â””â”€â”€ langsmith_integration.py       # Tracing utilities
â”œâ”€â”€ tests/                             # Unit tests
â”‚   â””â”€â”€ test_imports.py
â”œâ”€â”€ docs/                              # Documentation
â”‚   â””â”€â”€ RESPONSIBLE_AI.md
â”œâ”€â”€ assets/                            # Images and diagrams
â”‚   â””â”€â”€ diagram_placeholder.png
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml                     # CI/CD pipeline
```

### Adding New Features

1. Implement the feature in `src/`
2. Add corresponding tests in `tests/`
3. Create or update a notebook demonstrating usage
4. Update documentation
5. Run CI checks: `pytest tests/`

### CI/CD

The GitHub Actions workflow (`.github/workflows/ci.yml`) automatically:
- Sets up Python environment
- Installs dependencies
- Runs pytest on all tests
- Validates that modules can be imported
- **Runs without API keys** using dry-run mode

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

1. Fork the repository
2. Create a feature branch
3. Make your changes with clear commit messages
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- GDPR regulation text from official EU sources
- LangChain and LangGraph frameworks
- OpenAI for embeddings and language models
- FAISS for efficient vector search

## ğŸ“ Support

For questions or issues:
- Open a GitHub issue
- Check existing documentation in `docs/`
- Review notebook examples in `notebooks/`

## ğŸ”— Resources

- [LangChain Documentation](https://python.langchain.com/)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [LangSmith Documentation](https://docs.smith.langchain.com/)
- [FAISS Documentation](https://faiss.ai/)
- [GDPR Official Text](https://eur-lex.europa.eu/eli/reg/2016/679/oj)
