{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Milestone 3: Memory Integration with LangGraph\n",
        "\n",
        "This notebook demonstrates conversation memory integration:\n",
        "1. Create conversation memory\n",
        "2. Integrate memory with RAG system\n",
        "3. Test multi-turn conversations\n",
        "4. Implement LangGraph-based chat agent\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from src import memory, rag_baseline\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "print(\"Memory module loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create Conversation Memory\n",
        "\n",
        "Initialize a conversation memory buffer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create conversation memory\n",
        "conv_memory = memory.ConversationMemory(max_history=10)\n",
        "\n",
        "print(\"Conversation memory created\")\n",
        "print(f\"Max history: {conv_memory.max_history} turns\")\n",
        "print(f\"Current history: {len(conv_memory.history)} messages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Test Memory Operations\n",
        "\n",
        "Add conversation turns and retrieve history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add conversation turns\n",
        "conv_memory.add_turn(\n",
        "    \"What is GDPR?\",\n",
        "    \"GDPR is the General Data Protection Regulation...\"\n",
        ")\n",
        "\n",
        "conv_memory.add_turn(\n",
        "    \"When did it come into effect?\",\n",
        "    \"It came into effect on May 25, 2018.\"\n",
        ")\n",
        "\n",
        "conv_memory.add_turn(\n",
        "    \"What are the key principles?\",\n",
        "    \"The key principles include lawfulness, fairness, and transparency...\"\n",
        ")\n",
        "\n",
        "# Display history\n",
        "print(\"\\nConversation History:\")\n",
        "print(\"=\" * 60)\n",
        "print(conv_memory.format_for_prompt())\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Integrate Memory with RAG\n",
        "\n",
        "Create a memory-enabled RAG system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create base RAG\n",
        "base_rag = rag_baseline.BaselineRAG()\n",
        "\n",
        "# Create memory-enabled RAG\n",
        "memory_rag = memory.MemoryEnabledRAG(\n",
        "    base_rag=base_rag,\n",
        "    memory=conv_memory\n",
        ")\n",
        "\n",
        "print(\"✅ Memory-enabled RAG created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Test Multi-turn Conversation\n",
        "\n",
        "Simulate a conversation where context from previous turns matters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear previous history\n",
        "memory_rag.clear_history()\n",
        "\n",
        "# Conversation sequence\n",
        "conversation = [\n",
        "    \"What is personal data?\",\n",
        "    \"Can you give me examples?\",\n",
        "    \"How should it be protected?\"\n",
        "]\n",
        "\n",
        "print(\"Multi-turn conversation:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, question in enumerate(conversation, 1):\n",
        "    print(f\"\\nTurn {i}:\")\n",
        "    print(f\"User: {question}\")\n",
        "    \n",
        "    result = memory_rag.query(question, use_history=True)\n",
        "    \n",
        "    print(f\"Assistant: {result['answer'][:150]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"\\nTotal turns in memory: {len(memory_rag.memory.history)//2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Compare With and Without Memory\n",
        "\n",
        "Show the difference between using memory vs. not using it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear history and start fresh\n",
        "memory_rag.clear_history()\n",
        "\n",
        "# First question\n",
        "q1 = \"Tell me about data processing principles\"\n",
        "r1 = memory_rag.query(q1)\n",
        "\n",
        "# Follow-up question (ambiguous without context)\n",
        "q2 = \"What are the exceptions?\"\n",
        "\n",
        "# Without memory\n",
        "print(\"WITHOUT MEMORY:\")\n",
        "print(f\"Q: {q2}\")\n",
        "result_no_memory = base_rag.query(q2)\n",
        "print(f\"A: {result_no_memory['answer'][:100]}...\\n\")\n",
        "\n",
        "# With memory\n",
        "print(\"WITH MEMORY:\")\n",
        "print(f\"Q: {q2}\")\n",
        "result_with_memory = memory_rag.query(q2, use_history=True)\n",
        "print(f\"A: {result_with_memory['answer'][:100]}...\")\n",
        "\n",
        "print(\"\\nNote: With memory, the system understands 'exceptions' refers to data processing principles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: LangGraph Agent Integration\n",
        "\n",
        "Create a LangGraph-based agent with memory (skeleton implementation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create LangGraph agent with memory\n",
        "agent_config = memory.create_memory_agent(conv_memory)\n",
        "\n",
        "print(\"LangGraph Agent Configuration:\")\n",
        "print(f\"  Type: {agent_config['type']}\")\n",
        "print(f\"  Checkpoint: {agent_config['checkpoint']}\")\n",
        "print(f\"  Memory: {type(agent_config['memory']).__name__}\")\n",
        "\n",
        "print(\"\\nNote: Full LangGraph implementation requires additional setup\")\n",
        "print(\"See src/memory.py for TODOs and implementation notes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we:\n",
        "- ✅ Created conversation memory buffer\n",
        "- ✅ Integrated memory with RAG system\n",
        "- ✅ Tested multi-turn conversations\n",
        "- ✅ Compared performance with/without memory\n",
        "- ✅ Explored LangGraph agent integration\n",
        "\n",
        "Next: Proceed to `04_guardrails.ipynb` to implement safety filters."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
