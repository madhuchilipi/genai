{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Baseline RAG Pipeline\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading the FAISS index\n",
    "2. Implementing basic retrieval\n",
    "3. Prompt formatting with context\n",
    "4. LLM answer generation\n",
    "5. Evaluation metrics\n",
    "\n",
    "**Prerequisites**: Complete Notebook 1 (Data Preparation) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.rag_baseline import BaselineRAG, evaluate_retrieval\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"OpenAI API Key configured: {'Yes' if os.getenv('OPENAI_API_KEY') else 'No (dry-run mode)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Baseline RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG system\n",
    "rag = BaselineRAG(\n",
    "    faiss_path=\"faiss_index/\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "print(\"✓ Baseline RAG initialized\")\n",
    "print(f\"Model: {rag.model}\")\n",
    "print(f\"Top-K: {rag.top_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries\n",
    "test_queries = [\n",
    "    \"What are the data subject rights under GDPR?\",\n",
    "    \"What is the right to erasure?\",\n",
    "    \"What are the lawful bases for processing personal data?\"\n",
    "]\n",
    "\n",
    "# Run queries\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = rag.query(query)\n",
    "    \n",
    "    print(f\"\\nAnswer:\\n{result['answer']}\")\n",
    "    print(f\"\\nSources: {result['num_sources']} documents\")\n",
    "    for i, source in enumerate(result['sources'], 1):\n",
    "        print(f\"  {i}. Article {source.get('article', '?')}, Page {source.get('page', '?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate Retrieval Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve documents for evaluation\n",
    "query = \"What are the data subject rights?\"\n",
    "retrieved_docs = rag.retrieve(query)\n",
    "\n",
    "# Ground truth: Articles 15-22 cover data subject rights\n",
    "ground_truth = [15, 16, 17, 18, 19, 20, 21, 22]\n",
    "\n",
    "# Evaluate retrieval\n",
    "metrics = evaluate_retrieval(retrieved_docs, ground_truth)\n",
    "\n",
    "print(f\"\\nRetrieval Evaluation:\")\n",
    "print(f\"  Precision: {metrics['precision']:.2%}\")\n",
    "print(f\"  Recall: {metrics['recall']:.2%}\")\n",
    "print(f\"  F1 Score: {metrics['f1']:.2%}\")\n",
    "print(f\"\\nRetrieved Articles: {metrics['retrieved_articles']}\")\n",
    "print(f\"Ground Truth Articles: {metrics['ground_truth']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Prompt Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the formatted prompt\n",
    "query = \"What is the right to data portability?\"\n",
    "docs = rag.retrieve(query)\n",
    "prompt = rag.format_prompt(query, docs)\n",
    "\n",
    "print(\"Formatted Prompt:\")\n",
    "print(\"=\"*60)\n",
    "print(prompt)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "- ✓ Initialized a baseline RAG system\n",
    "- ✓ Ran sample GDPR queries\n",
    "- ✓ Evaluated retrieval quality\n",
    "- ✓ Analyzed prompt structure\n",
    "\n",
    "Next: Notebook 3 - Memory Integration with LangGraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
