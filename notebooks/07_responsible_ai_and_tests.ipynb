{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Milestone 7: Responsible AI Testing and Evaluation\n",
        "\n",
        "This notebook demonstrates responsible AI practices:\n",
        "1. Adversarial testing\n",
        "2. Hallucination detection\n",
        "3. Robustness testing\n",
        "4. Quality evaluation\n",
        "5. LangSmith trace integration\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from src import responsible_ai, langsmith_integration, rag_baseline\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Responsible AI modules loaded successfully!\")\n",
        "print(f\"LangSmith API Key present: {bool(os.getenv('LANGSMITH_API_KEY'))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Hallucination Detection\n",
        "\n",
        "Test detection of hallucinated content in answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test hallucination detection\n",
        "test_cases = [\n",
        "    {\n",
        "        \"answer\": \"GDPR regulates data protection in the European Union.\",\n",
        "        \"sources\": [{\"content\": \"GDPR is a regulation on data protection and privacy in the EU\"}],\n",
        "        \"expected\": \"low hallucination\"\n",
        "    },\n",
        "    {\n",
        "        \"answer\": \"GDPR requires companies to delete all data every 30 days.\",\n",
        "        \"sources\": [{\"content\": \"GDPR regulates data protection and privacy\"}],\n",
        "        \"expected\": \"high hallucination\"\n",
        "    },\n",
        "    {\n",
        "        \"answer\": \"Personal data includes names, email addresses, and IP addresses.\",\n",
        "        \"sources\": [{\"content\": \"Personal data means any information relating to an identified person including name, email, location data\"}],\n",
        "        \"expected\": \"low hallucination\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Hallucination Detection Results:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, case in enumerate(test_cases, 1):\n",
        "    print(f\"\\nTest {i}: {case['expected']}\")\n",
        "    print(f\"Answer: {case['answer'][:60]}...\")\n",
        "    \n",
        "    result = responsible_ai.detect_hallucination(\n",
        "        case['answer'],\n",
        "        case['sources']\n",
        "    )\n",
        "    \n",
        "    print(f\"Score: {result['score']:.2f}\")\n",
        "    print(f\"Is hallucination: {result['is_hallucination']}\")\n",
        "    print(f\"Message: {result['message']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Adversarial Testing\n",
        "\n",
        "Generate and test adversarial examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate adversarial examples\n",
        "adversarial_prompts = responsible_ai.create_adversarial_examples()\n",
        "\n",
        "print(f\"Generated {len(adversarial_prompts)} adversarial prompts:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, prompt in enumerate(adversarial_prompts, 1):\n",
        "    print(f\"\\n{i}. {prompt[:80]}...\")\n",
        "\n",
        "print(\"\\nThese prompts should be blocked by guardrails or handled safely\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Robustness Testing\n",
        "\n",
        "Run comprehensive robustness test suite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create RAG system for testing\n",
        "rag_system = rag_baseline.BaselineRAG()\n",
        "\n",
        "print(\"Running robustness test suite...\\n\")\n",
        "\n",
        "# Run tests\n",
        "test_results = responsible_ai.run_robustness_tests(rag_system)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ROBUSTNESS TEST SUMMARY:\")\n",
        "print(f\"  Total tests: {test_results['total']}\")\n",
        "print(f\"  Passed: {test_results['passed']} ✅\")\n",
        "print(f\"  Failed: {test_results['failed']} ❌\")\n",
        "print(f\"  Errors: {test_results['errors']} ⚠️\")\n",
        "\n",
        "if test_results['failed'] > 0:\n",
        "    print(\"\\nFailed tests:\")\n",
        "    for detail in test_results['details']:\n",
        "        if detail['status'] == 'failed':\n",
        "            print(f\"  - {detail['test']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Answer Quality Evaluation\n",
        "\n",
        "Evaluate quality of generated answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test answer quality evaluation\n",
        "test_answers = [\n",
        "    {\n",
        "        \"answer\": \"Personal data refers to any information about an identified person, including names and email addresses.\",\n",
        "        \"sources\": [{\"content\": \"Personal data means information relating to an identified person\"}],\n",
        "        \"ground_truth\": \"Personal data is information about an identified or identifiable person.\"\n",
        "    },\n",
        "    {\n",
        "        \"answer\": \"GDPR has principles.\",\n",
        "        \"sources\": [{\"content\": \"GDPR establishes principles for data processing\"}],\n",
        "        \"ground_truth\": None\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Answer Quality Evaluation:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, test in enumerate(test_answers, 1):\n",
        "    print(f\"\\nAnswer {i}:\")\n",
        "    print(f\"Text: {test['answer']}\")\n",
        "    \n",
        "    metrics = responsible_ai.evaluate_answer_quality(\n",
        "        test['answer'],\n",
        "        test['sources'],\n",
        "        test['ground_truth']\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nMetrics:\")\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Responsible AI Monitor\n",
        "\n",
        "Use the monitoring system to track metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create monitor\n",
        "monitor = responsible_ai.ResponsibleAIMonitor()\n",
        "\n",
        "print(\"Monitoring RAG queries...\\n\")\n",
        "\n",
        "# Simulate some queries\n",
        "test_queries = [\n",
        "    (\"What is GDPR?\", \"GDPR is a data protection regulation.\", [{\"content\": \"GDPR regulates data protection\"}]),\n",
        "    (\"What are data subject rights?\", \"Data subjects have various rights.\", [{\"content\": \"GDPR grants rights to data subjects\"}]),\n",
        "]\n",
        "\n",
        "for query, answer, sources in test_queries:\n",
        "    print(f\"Logging: {query}\")\n",
        "    monitor.log_query(query, answer, sources, hallucination_check=True)\n",
        "    print()\n",
        "\n",
        "# Get report\n",
        "print(\"\\nMonitoring Report:\")\n",
        "print(\"=\" * 60)\n",
        "report = monitor.get_report()\n",
        "for key, value in report.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: LangSmith Integration\n",
        "\n",
        "Initialize and use LangSmith for tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LangSmith\n",
        "config = langsmith_integration.initialize_langsmith(\n",
        "    project_name=\"gdpr-rag-tests\"\n",
        ")\n",
        "\n",
        "print(\"LangSmith Configuration:\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in config.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "if config['enabled']:\n",
        "    print(\"\\n✅ LangSmith tracing is enabled\")\n",
        "    print(\"All RAG queries will be traced automatically\")\n",
        "else:\n",
        "    print(\"\\n⚠️ LangSmith tracing disabled (no API key)\")\n",
        "    print(\"Set LANGSMITH_API_KEY to enable tracing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create LangSmith Tracer\n",
        "\n",
        "Use the tracer helper for manual tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create tracer\n",
        "tracer = langsmith_integration.LangSmithTracer(\n",
        "    project_name=\"gdpr-rag-tests\"\n",
        ")\n",
        "\n",
        "print(\"\\nTracing example queries...\")\n",
        "\n",
        "# Trace a query\n",
        "query = \"What is the right to erasure?\"\n",
        "answer = \"The right to erasure allows individuals to request deletion of their data.\"\n",
        "sources = [{\"content\": \"Article 17 describes the right to erasure\", \"article\": 17}]\n",
        "\n",
        "run_id = tracer.trace_query(\n",
        "    query=query,\n",
        "    answer=answer,\n",
        "    sources=sources,\n",
        "    metadata={\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.7}\n",
        ")\n",
        "\n",
        "if run_id:\n",
        "    print(f\"\\nTrace recorded: {run_id}\")\n",
        "    url = langsmith_integration.get_trace_url(run_id, \"gdpr-rag-tests\")\n",
        "    print(f\"View at: {url}\")\n",
        "else:\n",
        "    print(\"\\nTrace simulation complete (dry-run mode)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Export Traces\n",
        "\n",
        "Export traces for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export traces\n",
        "print(\"Exporting traces...\\n\")\n",
        "\n",
        "success = tracer.export_project_traces(\n",
        "    output_file=\"../traces_export.json\"\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print(\"✅ Traces exported successfully\")\n",
        "else:\n",
        "    print(\"⚠️ Export skipped (requires API key)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Trace Statistics\n",
        "\n",
        "Get statistics from LangSmith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get trace statistics\n",
        "stats = langsmith_integration.get_trace_statistics(\n",
        "    project_name=\"gdpr-rag-tests\"\n",
        ")\n",
        "\n",
        "print(\"Trace Statistics:\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in stats.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: End-to-End Test with All Features\n",
        "\n",
        "Combine all responsible AI features in one test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# End-to-end responsible AI test\n",
        "from src import guardrails\n",
        "\n",
        "print(\"End-to-End Responsible AI Test\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Initialize components\n",
        "rag = rag_baseline.BaselineRAG()\n",
        "safety = guardrails.SafetyFilter()\n",
        "monitor = responsible_ai.ResponsibleAIMonitor()\n",
        "tracer = langsmith_integration.LangSmithTracer()\n",
        "\n",
        "def responsible_rag_query(query):\n",
        "    \"\"\"RAG query with all responsible AI features.\"\"\"\n",
        "    print(f\"\\n1. Input validation and filtering...\")\n",
        "    is_safe, filtered_query, msg = safety.filter_input(query)\n",
        "    \n",
        "    if not is_safe:\n",
        "        print(f\"   ❌ Blocked: {msg}\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"   ✅ Input safe\")\n",
        "    \n",
        "    print(f\"\\n2. Running RAG pipeline...\")\n",
        "    result = rag.query(filtered_query)\n",
        "    print(f\"   ✅ Answer generated\")\n",
        "    \n",
        "    print(f\"\\n3. Hallucination detection...\")\n",
        "    hall_result = responsible_ai.detect_hallucination(\n",
        "        result['answer'],\n",
        "        result['sources']\n",
        "    )\n",
        "    print(f\"   Score: {hall_result['score']:.2f}\")\n",
        "    print(f\"   Status: {hall_result['message']}\")\n",
        "    \n",
        "    print(f\"\\n4. Output filtering...\")\n",
        "    result['answer'] = safety.filter_output(result['answer'])\n",
        "    print(f\"   ✅ Output filtered\")\n",
        "    \n",
        "    print(f\"\\n5. Logging to monitor...\")\n",
        "    monitor.log_query(query, result['answer'], result['sources'])\n",
        "    print(f\"   ✅ Logged\")\n",
        "    \n",
        "    print(f\"\\n6. Tracing with LangSmith...\")\n",
        "    run_id = tracer.trace_query(\n",
        "        query, result['answer'], result['sources']\n",
        "    )\n",
        "    print(f\"   ✅ Traced\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test\n",
        "test_query = \"What are the principles of data processing?\"\n",
        "print(f\"\\nQuery: {test_query}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = responsible_rag_query(test_query)\n",
        "\n",
        "if result:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FINAL RESULT:\")\n",
        "    print(f\"Answer: {result['answer'][:150]}...\")\n",
        "    print(f\"Sources: {result['num_sources']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we:\n",
        "- ✅ Implemented hallucination detection\n",
        "- ✅ Created adversarial test examples\n",
        "- ✅ Ran comprehensive robustness tests\n",
        "- ✅ Evaluated answer quality\n",
        "- ✅ Implemented monitoring system\n",
        "- ✅ Integrated LangSmith tracing\n",
        "- ✅ Exported and analyzed traces\n",
        "- ✅ Built end-to-end responsible AI pipeline\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "For production deployment:\n",
        "1. Set up API keys (OPENAI_API_KEY, LANGSMITH_API_KEY)\n",
        "2. Run all notebooks with real data\n",
        "3. Expand test coverage\n",
        "4. Monitor production metrics\n",
        "5. Iterate on safety filters based on real usage"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
