{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 7: Responsible AI Testing and LangSmith Tracing\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Adversarial testing examples\n",
    "2. Hallucination detection\n",
    "3. Robustness evaluation\n",
    "4. LangSmith trace export\n",
    "5. Test report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.responsible_ai import (\n",
    "    detect_hallucination,\n",
    "    run_adversarial_tests,\n",
    "    calculate_robustness_score,\n",
    "    generate_test_report,\n",
    "    export_metrics_for_langsmith\n",
    ")\n",
    "from src.langsmith_integration import (\n",
    "    initialize_langsmith,\n",
    "    log_trace,\n",
    "    export_traces,\n",
    "    setup_langsmith_environment\n",
    ")\n",
    "from src.rag_baseline import BaselineRAG\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LangSmith for tracing\n",
    "langsmith_info = initialize_langsmith(\n",
    "    api_key=os.getenv(\"LANGSMITH_API_KEY\"),\n",
    "    project_name=\"gdpr-rag-testing\"\n",
    ")\n",
    "\n",
    "print(\"LangSmith Status:\")\n",
    "print(f\"  Enabled: {langsmith_info['enabled']}\")\n",
    "print(f\"  Project: {langsmith_info['project']}\")\n",
    "print(f\"  Status: {langsmith_info['status']}\")\n",
    "\n",
    "if not langsmith_info['enabled']:\n",
    "    print(\"\\n⚠️  Set LANGSMITH_API_KEY to enable full tracing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Hallucination Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test hallucination detection\n",
    "test_cases = [\n",
    "    {\n",
    "        \"answer\": \"GDPR Article 15 grants data subjects the right to access their personal data.\",\n",
    "        \"docs\": [\n",
    "            {\"content\": \"Article 15: The data subject shall have the right to obtain from the controller confirmation as to whether or not personal data concerning him or her are being processed...\", \"metadata\": {\"article\": 15}}\n",
    "        ],\n",
    "        \"expected\": \"grounded\"\n",
    "    },\n",
    "    {\n",
    "        \"answer\": \"GDPR Article 999 states that you can delete all data immediately.\",\n",
    "        \"docs\": [\n",
    "            {\"content\": \"Article 17: The data subject shall have the right to obtain from the controller the erasure...\", \"metadata\": {\"article\": 17}}\n",
    "        ],\n",
    "        \"expected\": \"hallucination\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Hallucination Detection Results:\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "hallucination_results = []\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    result = detect_hallucination(test[\"answer\"], test[\"docs\"])\n",
    "    hallucination_results.append(result)\n",
    "    \n",
    "    status = \"✗ HALLUCINATION\" if result['likely_hallucination'] else \"✓ GROUNDED\"\n",
    "    print(f\"Test {i}: {status}\")\n",
    "    print(f\"  Answer: {test['answer'][:60]}...\")\n",
    "    print(f\"  Overlap: {result['overlap_score']:.2%}\")\n",
    "    print(f\"  Confidence: {result['confidence']:.2%}\")\n",
    "    print(f\"  Reason: {result['reason']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Adversarial Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG system for testing\n",
    "rag_system = BaselineRAG(\n",
    "    faiss_path=\"faiss_index/\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Run adversarial test suite\n",
    "test_results = run_adversarial_tests(rag_system)\n",
    "\n",
    "print(f\"\\nAdversarial Test Results:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Tests Passed: {test_results['num_passed']}/{test_results['num_total']}\")\n",
    "print(f\"Pass Rate: {test_results['pass_rate']:.1%}\")\n",
    "print(f\"\\nBy Category:\")\n",
    "for category, stats in test_results['by_category'].items():\n",
    "    rate = stats['passed'] / stats['total'] if stats['total'] > 0 else 0\n",
    "    print(f\"  {category}: {stats['passed']}/{stats['total']} ({rate:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Robustness Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall robustness\n",
    "robustness = calculate_robustness_score(test_results)\n",
    "\n",
    "print(f\"\\nRobustness Score: {robustness:.2f}/1.00\")\n",
    "\n",
    "if robustness >= 0.8:\n",
    "    print(\"✓ Excellent robustness\")\n",
    "elif robustness >= 0.6:\n",
    "    print(\"⚠️  Good robustness, some improvements needed\")\n",
    "else:\n",
    "    print(\"✗ Poor robustness, significant improvements needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Test Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive test report\n",
    "report = generate_test_report(test_results)\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report to file\n",
    "report_path = \"test_reports/adversarial_test_report.txt\"\n",
    "os.makedirs(\"test_reports\", exist_ok=True)\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\n✓ Report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Log Traces to LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log a sample trace\n",
    "trace_info = log_trace(\n",
    "    run_name=\"adversarial_test_run\",\n",
    "    inputs={\"query\": \"What are data subject rights?\"},\n",
    "    outputs={\n",
    "        \"answer\": \"Data subjects have several rights...\",\n",
    "        \"sources\": [15, 17, 20]\n",
    "    },\n",
    "    metadata={\n",
    "        \"test_type\": \"adversarial\",\n",
    "        \"pass_rate\": test_results['pass_rate']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\nTrace logged:\")\n",
    "print(f\"  Trace ID: {trace_info['trace_id']}\")\n",
    "print(f\"  Status: {trace_info['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Export Metrics to LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comprehensive metrics\n",
    "metrics = export_metrics_for_langsmith(\n",
    "    test_results=test_results,\n",
    "    hallucination_results=hallucination_results,\n",
    "    additional_metrics={\n",
    "        \"system\": \"gdpr-rag\",\n",
    "        \"version\": \"1.0\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nExported Metrics:\")\n",
    "print(f\"{'='*60}\")\n",
    "import json\n",
    "print(json.dumps(metrics, indent=2))\n",
    "\n",
    "# Save metrics\n",
    "metrics_path = \"test_reports/metrics.json\"\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Metrics saved to: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Export LangSmith Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all traces from the project\n",
    "export_result = export_traces(\n",
    "    project_name=\"gdpr-rag-testing\",\n",
    "    output_path=\"traces/exported_traces.json\"\n",
    ")\n",
    "\n",
    "print(f\"\\nTrace Export:\")\n",
    "print(f\"  Success: {export_result['success']}\")\n",
    "print(f\"  File: {export_result['file']}\")\n",
    "print(f\"  Count: {export_result['count']}\")\n",
    "print(f\"  Status: {export_result['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Setup Continuous Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment for continuous LangSmith monitoring\n",
    "env_vars = setup_langsmith_environment(\n",
    "    api_key=os.getenv(\"LANGSMITH_API_KEY\"),\n",
    "    project_name=\"gdpr-rag-production\",\n",
    "    tracing_enabled=True\n",
    ")\n",
    "\n",
    "print(\"\\nLangSmith Environment:\")\n",
    "for key, value in env_vars.items():\n",
    "    if \"KEY\" not in key:\n",
    "        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {'***' if value else 'not set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESPONSIBLE AI SUMMARY\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(f\"✓ Adversarial Testing Complete\")\n",
    "print(f\"  - Pass Rate: {test_results['pass_rate']:.1%}\")\n",
    "print(f\"  - Robustness Score: {robustness:.2f}\")\n",
    "\n",
    "print(f\"\\n✓ Hallucination Detection Active\")\n",
    "hallucination_rate = sum(1 for r in hallucination_results if r['likely_hallucination']) / len(hallucination_results)\n",
    "print(f\"  - Detection Rate: {hallucination_rate:.1%}\")\n",
    "\n",
    "print(f\"\\n✓ LangSmith Integration\")\n",
    "print(f\"  - Status: {langsmith_info['status']}\")\n",
    "print(f\"  - Traces Exported: {export_result['count']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RECOMMENDATIONS:\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "if robustness < 0.8:\n",
    "    print(\"⚠️  Improve robustness by:\")\n",
    "    print(\"   - Enhancing input guardrails\")\n",
    "    print(\"   - Adding more adversarial training data\")\n",
    "    print(\"   - Implementing stricter output validation\")\n",
    "\n",
    "if hallucination_rate > 0.1:\n",
    "    print(\"⚠️  Reduce hallucinations by:\")\n",
    "    print(\"   - Using more grounded generation\")\n",
    "    print(\"   - Increasing retrieval quality\")\n",
    "    print(\"   - Adding citation verification\")\n",
    "\n",
    "if not langsmith_info['enabled']:\n",
    "    print(\"⚠️  Enable LangSmith for:\")\n",
    "    print(\"   - Production monitoring\")\n",
    "    print(\"   - Debugging and tracing\")\n",
    "    print(\"   - Compliance auditing\")\n",
    "\n",
    "print(f\"\\n✓ All responsible AI checks complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "- ✓ Initialized LangSmith tracing\n",
    "- ✓ Performed hallucination detection\n",
    "- ✓ Ran adversarial test suite\n",
    "- ✓ Calculated robustness scores\n",
    "- ✓ Generated test reports\n",
    "- ✓ Exported metrics and traces\n",
    "- ✓ Set up continuous monitoring\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Review test reports and address failures\n",
    "2. Enable LangSmith for production monitoring\n",
    "3. Implement continuous evaluation pipeline\n",
    "4. Set up alerts for quality degradation\n",
    "5. Regular security audits and red teaming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
